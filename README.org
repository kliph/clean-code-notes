* Notes on Clean Code
By Robert C. Martin
* Foreword
By James O. Coplien

Sensible, but offers 0 evidence.  Retreads the tired ground of appealing to Eastern mysticism to back up the sensible advice.
* Introduction

Ah yes, anecdotal evidence.  You'll have to work "/hard/"to learn this stuff.  Hopefully there will be some evidence to back these heuristics up.  Maybe?

But really though, case studies and these sorts of heuristics seem great.  Sensible approaches to writing software are great.  Surely if these sensible approaches are so profoundly useful there should be a way to measure their usefulness.

I feel a real appeal to machismo and toxic masculinity in this book, when it tells me this is "/hard work/" in contrast to a "feel good" book you can read on a plane.  I feel the appeal to machismo and toxic masculinity when it mentions that you'll gain a rich understanding of "principles, patterns, practices, and heuristics ... in your gut, fingers, and heart."  I could do without it.

I don't need a condescending tone to guilt-trip me into accepting what you say.  If it's sensible, show me how to do it and I will.  If it's measurable, demonstrate its effectiveness.

Finally, the WTFs per minute cartoon is great :D.

** A note on axioms

It would seem that Martin and company are attempting to do deductive reasoning from axioms.  My Mac's dictionary defines the word axiom as: "a statement or proposition which is regarded as being established, accepted, or self-evidently true."

They readily admit that other people may disagree with the claims that they treat as axiomatic.

I disagree in principle that there is any basis to reason axiomatically (that is, deductively) in the field of software development.  Even the assumption that computers are governed by the mathematics more than physics, barring all outside factors clearly being governed by empirical reality, falls apart with a modicum of scrutiny.  Processors in our machines are bound by the laws of physics.  Our software runs on the hard drives, RAM, and CPUs in these machines.  Humans write the software for, as Martin asserts, the intended audience of humans.

I posit that software development is governed by the rules of physics and psychology, and that we would do well to consider the empirical study of these fields when trying to determine Truths about software development.

The [[https://en.wikipedia.org/wiki/Scientific_method#Relationship_with_mathematics][scientific method]] serves as a means to test the validity of so called "axioms" that I believe would be better termed "folk psychology."  I find myself firmly in the [[https://en.wikipedia.org/wiki/Eliminative_materialism][school of thought espoused by Patty Churchland and others]] that seeks to question the basis for these "axioms," or common-sense understandings if you will, in order to determine the True nature of reality to the best of our abilities.

* Chapter 1: Clean Code
#+caption: There Will Be +Code+ Blood
[[https://media.giphy.com/media/tt3eTxBT0cgtW/giphy.gif]]

The doctors hand-washing anecdote argues in favor of strong validation via evidence.  It does not suggest that doctors have the prestige and privilege to buck the system, going against what their managers say in order to do what's best for their bosses (patients).

Grady Booch mentions that code should be readable.  I'm interested in that concept, specifically because I reckon that two programmers could have wildly different subjective definitions for what makes a certain bit of code readable.  I wonder whether there is any research determining the parameters that feed into this concept of readability.  This [[https://faculty.washington.edu/ajko/books/cooperative-software-development/comprehension.html][chapter from Andrew J. Ko]]
 seems like a good resource.

For what it's worth, I agree with Booch that clean code should read like prose.

In the next section (covering "Big" Dave Thomas), Martin asserts that "[t]here is, after all, a difference between code that is easy to read and code that is easy to change."  I see no evidence to support this dichotomy.  It certainly seems possible that readability and changeability are polar opposites, but it also seems possible that many overlapping factors contribute to what we (assuming we both hold similar referents) term readability and changeability.  We can't just take these assumptions for granted /a priori/.  We must investigate and interrogate these assumptions to learn whether they can tell us any meaningful information about the world.

Martin also points out that Thomas mentions twice that smaller code is better.  This brings to mind the some of the work in Adam Tornhill's /[[https://pragprog.com/book/atcrime/your-code-as-a-crime-scene][Your Code as a Crime Scene]]/.  I should revisit that when I can find the time.  It would seem that there is an argument to be made in favor of smaller code bases given constant rates of errors (bugs).

Ron Jeffries makes an interesting point on refactoring to extract methods: "If it's a method, [refactor it], resulting in one method that says more clearly *what* it does, and some submethods saying *how* it is done." Bold indicates my emphasis.

Interesting that Martin's well-known programmers are all white men.  Might be interesting to ask a more diverse sample to share their opinions on what makes code "clean".  I don't presume that the findings would be too different, but one can't know without conducting the research.

Okay, so, comparing Martin's "School of Thought" to a martial arts tradition is a total cop out.  It's not as if martial arts traditions [[https://www.ncbi.nlm.nih.gov/pubmed/31191109][haven't]] [[https://www.ncbi.nlm.nih.gov/pubmed/31240587][been]] [[https://www.ncbi.nlm.nih.gov/pubmed/31373295][rigorously]] [[https://www.ncbi.nlm.nih.gov/pubmed/31343555][studied]] [[https://www.ncbi.nlm.nih.gov/pubmed/31336837][and]] [[https://www.ncbi.nlm.nih.gov/pubmed/31282402][tested]] [[https://www.ncbi.nlm.nih.gov/pubmed/31261524][for]] [[https://www.ncbi.nlm.nih.gov/pubmed/30846917][effectiveness]] (and I couldn't resist a [[https://www.ncbi.nlm.nih.gov/pubmed/30832454][couple]] [[https://www.ncbi.nlm.nih.gov/pubmed/30694967][more]]).  Why not do the same for these ideas that, at this point, "/are/ absolutes"?

[[https://media.giphy.com/media/sJiAhV5VPheTK/giphy.gif]]

#+BEGIN_QUOTE
In the 80s and 90s we had editors like Emacs that kept track of every keystroke.
#+END_QUOTE

LOL that's *rich*!  See [[https://en.wikipedia.org/wiki/Emacs#cite_note-1][these]] [[https://en.wikipedia.org/wiki/Emacs#cite_note-jwz_timeline-2][citations]] for more information.
* Chapter 2: Meaningful Names
by Tim Ottinger

Nice, choose names that communicate intent.  Seems reminiscent of Zach Tellman's /[[https://leanpub.com/elementsofclojure][Elements of Clojure]]/ and Bozhidar Batsov's [[https://guide.clojure.style/][Clojure Style Guide]] (not to mention, although pausing specifically to mention, Batsov's work on the [[https://rubystyle.guide/][Ruby Style Guide]]).

In the Make Meaningful Distinctions section, Ottinger mentions something I found very puzzling initially:

#+BEGIN_QUOTE
For example, because you can't use the same name to refer to two different things in the same scope, you might be tempted to change one name in an arbitrary way.  Sometimes this is done by misspelling one, leading to the surprising situation where correcting spelling errors leads to an inability to compile.
#+END_QUOTE

I've definitely encountered this!

In a footnote, Ottinger mentions using =klass= because =class= was used elsewhere.  See also:

#+BEGIN_SRC js
  var that = this;
#+END_SRC

I can certainly see why it would be necessary.  But still.  Yuck.

[[https://media.giphy.com/media/ZF32u4EqI0AHqUQucs/giphy.gif]]

"/The length of a name should correspond to the size of its scope./"  This is a nice heuristic and one I use myself.

Here's a hypothesis.  Seems like testing comprehension by varying name length by objective scope would be a relatively straightforward experiment.  Conditions could be "long names" for large scope / "short names" for small scope, "short names" for large scope / "long names" for small scope, random length names for all scopes, etc.

Not sure I buy the argument regarding Interfaces and Implementations.  Those seem to be cases where you have a meaningful distinction between multiple bits of code dealing with the same referent.  Ottinger seems to think it is necessary to use encodings for these cases, but using =I= as a prefix is "a distraction at best and too much information at worst."  =AbstractFoo=, =IFoo=, and =FooImpl= all make sense to me.

I'm totally here for picking one word per concept.  That's a practice I use all the time.

[[https://media.giphy.com/media/NEvPzZ8bd1V4Y/giphy.gif]]

Regarding the assumption that everyone who reads your code will be programmers, I say, "Uhhhh, not so sure that's always the case, but granted."  When Ottinger recommends using "computer science ... terms, algorithm names, pattern names, path terms and so forth."  I [[https://twitter.com/elementsofclj/status/1074710832938971136][disagree]].

It's incumbent on the author to define the terms for the reader.  I have often accomplished this by including a Glossary defining terms of art in a project.  This goes for domain-specific terms as well as general purpose terms which may or may not be used in novel ways to solve the problem at hand.

[[https://media.giphy.com/media/P5wPrhzZDdeJW/giphy.gif]]
* Chapter 3: Functions
Keep 'em tiny.

[[https://media.giphy.com/media/cOVtfbB28ejn0lk3sq/giphy.gif]]

There's a nice principle here that a function is doing one and only one thing if and only if you can no longer meaningfully refactor it into a function that is not merely a restatement of its implementation.  But who is to say that you and I agree on what meaningful refactoring are?  It would be helpful if there were some more objective way to define this.

I can see how the code in Listing 3-7 is refactored to make the functions as smol as possible.  And I can also see how nicely the logic and level of abstraction flows from function to function.  I like how each function introduces the next.  However, I don't see how this approach is objectively better than a more gestalt-oriented approach.

I'm reminded of [[https://neuro.wisc.edu/staff/jones-mathew-2/][Matt Jones]] teaching me about "lumpers" and "splitters" in science.  Lumpers tend to try to group similar ideas into a cohesive gestalt in order to gain some explanatory power through the agglomerated whole.  Splitters tend to try to gain explanatory power by breaking things down into their atomic parts and understanding the similarities among things that share similar parts.

The approach Martin is advocating for here seems to fall squarely in the splitter category.  I remain unconvinced, though, that the humans who are doing the programming can easily handle (today and two weeks from now) a class with, by my count, 5 pieces of internal state, 2 public methods, and 16 private methods.  I grant, as Martin mentions, that tooling can help with this.  Indeed, I leverage tooling to help with my poor recall all the time.  However, I would argue that the tradeoffs associated with breaking a single method into 23 things becomes a question of [[https://en.m.wikipedia.org/wiki/Memory_span][human memory span]], rather than platonic elegance.

[[https://media.giphy.com/media/PcfozPlZSzARO/giphy.gif]]

Also let me get in a jab that =SetupTeardownIncluder.java= is not a super descriptive name!  Maybe it's useful in context.

I'm reminded of inheriting some code responsible for plotting some data.  It had been factored down to such small functions that it was hard to follow what it was doing at all.  Each function did one thing, and the sum of those functions did generate the plots as intended.  But figuring out how to extend the functionality was extremely difficult due to the distribution of level of abstraction across all of these functions.  In my opinion an easier way to read that code was that a single function was responsible for generating a single graph and may call out to multiple DRYed out helper functions that could live at lower levels of abstraction.  I refactored it to allow that organization and I felt that that made the code more extensible.

Most of the recommendations in this chapter strike me as testable hypotheses rather than unassailable imperatives to be ignored at your own peril.  That being said, they seem sensible enough rules of thumb to follow.

Also, I see function arguments as an area where "modern IDEs", what I call tooling, can help.

* Chapter 4: Comments

Man you could write a thesis on the depiction of women in this book.

[[https://media.giphy.com/media/31UDILmnnQOjnKKoKB/giphy.gif]]

WTF is up with associating women with comments, you know the thing you're not supposed to do?

[[https://media.giphy.com/media/QjIz1AqkGTszK/giphy.gif]]

WTF is up with associating +a woman+ women (just got to the scolding mother in this chapter) with motherhood?

[[https://media.giphy.com/media/3ohzdOKC7b6VbCPGQo/giphy.gif]]

WTF is up with not asking any women about their definitions of clean code?

[[https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Commodore_Grace_M._Hopper%2C_USN_%28covered%29.jpg/1536px-Commodore_Grace_M._Hopper%2C_USN_%28covered%29.jpg]]

Martin seems to be crying out for [[https://en.m.wikipedia.org/wiki/Literate_programming][literate programming]] to help keep comments current, that is to say code-driven (and, in homoiconic languages, therefore, data-driven).

The failure to keep comments current and accurate is not a given.  Surely, just as clean code requires gumption on the part of the author, comments require gumption on the part of the author to maintain their accuracy and integrity.  Why then, on the subject of comments, is Martin comfortable with throwing in the towel?

I just don't get why clean comments aren't important.  Martin's thesis seems to be: All comments are bad except for a few, and you should feel bad if you write them.

[[https://media.giphy.com/media/VeB9ieebylsaN5Jw8p/giphy.gif]]

How is that productive?
* Chapter 5: Formatting
[[https://media.giphy.com/media/SF4aJKqEchIiY/giphy.gif]]

Set rules and automate their enforcement.

* Chapter 6: Objects and Data Structures

[[https://media.giphy.com/media/Ws9uuyPnZhUOSR8tjx/giphy.gif]]

The recommendations for abstraction are good, but they aren't the only way to work around these problems of leaky scope and coupling.

[[https://media.giphy.com/media/rEMU7AjqjvMLC/giphy.gif]]

For example, have a gander at this Rich Hickey [[https://www.youtube.com/watch?v=YR5WdGrpoug][talk]] ([[https://github.com/matthiasn/talk-transcripts/blob/master/Hickey_Rich/MaybeNot.md][transcript here]]).  Some useful information here: https://github.com/clojure/spec-alpha2/wiki/Schema-and-select.  Boils down to separating requiring an attribute (for a function to operate on) from the requirements of an attribute (for an aggregate of valid data).

* Chapter 7: Error Handling
By Michael Feathers

This is the author of /[[https://www.oreilly.com/library/view/working-effectively-with/0131177052/][Working Effectively with Legacy Code]]/.  I plan to read that next.

* Chapter 8: Boundaries
By James Grenning

Good advice about wrapping, and code that should probably live in the Service layer.  Unsurprisingly inappropriate cartoon smh.

"Learning Tests Are Better Than Free" is a good one.  I'll have to use that.

* Chapter 9: Unit Tests
FIRST acronym

Tests should be:

- Fast
- Independent
- Repeatable
- Self-validating
  - You shouldn't need to read through the logs to verify that a test passes.
- Timely

* Chapter 10: Classes
With Jeff Langr

Sweet!  A woman can read the Federalist Papers.  Finally a reasonable portrayal in one of these illustrations.

Totally agree that linting class variable, method, etc. organization is probably a good idea.

I noticed an interesting issue with Single Responsibility Principle (SRP).  Here's the argument:

#+BEGIN_QUOTE
...[A] system with many small classes has no more moving parts than a system with a few large classes.
#+END_QUOTE

This argument seems to fail to account for levels of abstraction.  At each level of abstraction, in my opinion, the number of classes should be smaller than the human programmer's memory span.  This makes a nice hypothesis that could be tested straightforward in an undergraduate academic programming assignment.

Furthermore, the claim above that a system with small classes is just as comprehensible as a system with large classes is a hypothesis and should be similarly tested.

According to the index, SOLID only appears in this chapter.  I can't find any mention of it in the text.

[[https://media.giphy.com/media/l2YWupKFW0WnTeoco/giphy.gif]]


Anyway here's the lowdown on SOLID:

- S :: Classes should have a single responsibility
- O :: Classes should be open, meaning extensible, and closed over the state they contain so that it cannot be mutated
- L :: Liskov substitution which means that subclasses should return similar types, this is where the "substitution" comes in, to their parent classes.
- I :: Part of keeping classes open is that they should only implement the interfaces required for their functionality.
- D :: Use dependency inversions by writing classes that depend on abstractions not concrete implementations.
* Chapter 11: Systems
By Dr. Kevin Dean Wampler

The note about avoiding convenient idioms because they percolate into a codebase is good advice.  It should also be easily analyzed and characterized from version control history.

[[https://dl.acm.org/citation.cfm?id=542553][Software Physics by Kolence]] looks interesting.  Also interesting that Wampler points out psychological resistance to discarding prior effort, or the [[https://en.wikipedia.org/wiki/Sunk_cost#The_sunk_cost_effect][sunk cost fallacy]].

Feels like Wampler is describing the sorts of thing https://github.com/tolitius/mount =component= do more or less.

* Chapter 12: Emergence
By Jeff Langr

Really not getting anything new here.

* Chapter 13: Concurrency
By Brett L. Schuchert

Nice to see a recommendation to experiment and not treat the advice here as dogma.

Guidelines on testing threaded code seem helpful.

* Chapter 14: Successive Refinement
Not sure where this came up in the earlier text, but Martin's insistence on wrapping setters and getters to abstract away implementation detail works great for simple value types like =Int= or =Double=, but seems to open up refactoring problems when you don't fully understand the types of the values in your system and need to change from =Thing= to =Item= or whatever.

That being said, the approach of wrapping setters and getters means that you can take a code-driven approach to refactoring and let your tooling handle the work.  You'll never have one-off instances where you think you're getting the same value but the way you get it is slightly different so it breaks after refactoring.

This footnote seems to gloss over the whole point of the book:

#+BEGIN_QUOTE
I recently rewrote this module in Ruby.  It was 1/7th the size and had a subtly better structure.
#+END_QUOTE

In what way was the structure "subtly better"?  Wouldn't that distinction be important to communicate to the readers of the book whom you are trying to educate about the heuristics for best writing good code?

[[https://media.giphy.com/media/KZk7iygO3kuRNnTSAL/giphy.gif]]

* Chapter 15: JUnit Internals

Saying that no module is free from improvement seems to be self-fulfilling prophecy that gets us into a vicious loop where there will always be code, and that code will need to be improved to meet some ill-defined, subjective standard.

Cleanliness is then in the eye of the beholder.  Give 100 developers your code in series and you'll get 100 so-called improvements to that code.  You will pay the developers for their time 100-times over.  I anticipate that you will see diminishing returns in quality and even regressions (not in the sense of failing tests).

I'm taking a pretty pessimistic view here, but these arguments based on subjective definitions of what's good simply can't stand.  There has to be some objective ideal that you are improving toward or else you're just doing busy-work.

* Chapter 16: Refactoring =SerialDate=

** A note on critique

*Agreed that critique is good and should not be taken personally.  This document is intended to be this sort of critique.*

* Chapter 17: Smells and Heuristics

I'm going to highlight the ones I want to reference.

** Comments
- Obsolete comment :: Get rid of it or update it so that it's accurate.  It's incumbent on the folks writing and reviewing the code to ensure that comments are accurate.

** Environments
You should be able to build the code in a single step.

Similarly you should be able to test the code in a single step.

Hmm sounds pretty similar to [[https://github.com/github/scripts-to-rule-them-all][Scripts to Rule Them All]].

** General
- Functions should descend only one level of abstraction

** Names
- Choose names at the appropriate level of abstraction
  - Instead of =dial= choose =connect= for a phone dialing system to keep it agnostic about the underlying data format (i.e. Phone Numbers instead of some other method for locating users to =connect=)
